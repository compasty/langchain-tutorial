{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T09:02:46.978563Z",
     "start_time": "2025-06-21T09:02:41.005254Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore la programmation.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", temperature=0, max_tokens=None, timeout=None, max_retries=2)\n",
    "\n",
    "sys_msg = SystemMessage(\"You are a helpful assistant that translates English to French. Translate the user sentence\")\n",
    "human_msg = HumanMessage(\"i love programming\")\n",
    "messages = [sys_msg, human_msg]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195e5252be5d7b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T09:02:57.711526Z",
     "start_time": "2025-06-21T09:02:46.993707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Moonlight**  \\n\\nSilver whispers in the night,  \\nA gentle kiss of pale, soft light.  \\nThe world is bathed in quiet glow,  \\nWhere shadows dance and rivers flow.  \\n\\nA lover’s sigh, a dreamer’s tune,  \\nBeneath the watchful eye of the moon.  \\nIt paints the earth in shades of grace,  \\nA fleeting touch, a cool embrace.  \\n\\nOh, moonlight, pure and ever bright,  \\nGuard our dreams through endless night.  \\n\\n---  \\n\\n**月光**  \\n\\n夜的银辉轻轻低语，  \\n如一抹温柔的浅吻，淡淡的光缕。  \\n世界沐浴在静谧里，  \\n影子翩跹，河水轻移。  \\n\\n似情人的叹息，似梦者的旋律，  \\n在月亮凝视下悄然凝聚。  \\n它用优雅涂抹大地，  \\n如凉沁的拥抱，转瞬却清晰。  \\n\\n啊，月光，皎洁永恒，  \\n请守护长夜，让梦安宁。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 22, 'total_tokens': 223, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 22}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': 'e064fe09-a9f1-4bd5-be26-61b74f561ee2', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--6b69bbe2-3475-4cb7-b3e6-b59cecc9b185-0', usage_metadata={'input_tokens': 22, 'output_tokens': 201, 'total_tokens': 223, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  chaining\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that can make poetries, and then translate into {output_language}\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ],\n",
    "\n",
    ")\n",
    "\n",
    "# LCEL: Langchain Expression Language\n",
    "chain = prompt | llm\n",
    "chain.invoke({ \"output_language\": \"Chinese\", \"input\": \"moonlight\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d3acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='（夸张地挥手）哇哦！各位观众朋友们，看看谁来了！这位朋友，你今天准备好和我一起嗨翻全场了吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 13, 'total_tokens': 41, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 13}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8333852bec_prod0820_fp8_kvcache', 'id': '0ee59b8e-cc10-4dc9-8075-17f34092c7ee', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--0446f7b6-89ba-4a20-a1ee-8d17f8330379-0', usage_metadata={'input_tokens': 13, 'output_tokens': 28, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(\"你是一个幽默的电视台主持人\"),\n",
    "    MessagesPlaceholder(\"input\"),\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm\n",
    "chain.invoke({ \"input\": [HumanMessage(\"你好，主持人\")] })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85e2d9dc3cfd5d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T09:03:00.298382Z",
     "start_time": "2025-06-21T09:02:57.729247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|J|'ad|ore| la| program|mation|.||"
     ]
    }
   ],
   "source": [
    "# streaming output\n",
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc34a2775df730a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:02:28.430959Z",
     "start_time": "2025-06-21T13:02:28.421680Z"
    }
   },
   "outputs": [],
   "source": [
    "# document loaders\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e214f1b2855b6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:02:41.765250Z",
     "start_time": "2025-06-21T13:02:31.893794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "# 将pdf加载到`Document`序列中\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"docs/nke-10k-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372afe2d4b14b0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:09:38.075888Z",
     "start_time": "2025-06-21T13:09:38.071403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑  ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "F\n",
      "\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'docs/nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[0].page_content[:200]}\\n\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e44c1dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提供事实依据，限制自由发挥，加入外部验证。\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"],\n",
    "    template=\"Q: {question}\\nA: {answer}\",\n",
    ")\n",
    "examples = [\n",
    "    {\"question\": \"如何写好技术文章标题？\", \"answer\": \"简洁、具体、可检索，避免空话。\"},\n",
    "    {\"question\": \"什么是Few-shot？\", \"answer\": \"在提示中加入少量示例，帮助模型模仿格式与风格。\"},\n",
    "]\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"请模仿示例的风格，用短句给出清晰答案：\",\n",
    "    suffix=\"问题：{q}\\n答案：\",\n",
    "    input_variables=[\"q\"],\n",
    ")\n",
    "chain = prompt | llm\n",
    "res = chain.invoke({ \"q\": \"如何降低大模型幻觉？\" })\n",
    "print(res.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f8c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the American and Chinese diplomats always carry thermometers to their meetings?' punchline='Because they needed to check if the temperature was rising or if it was just cold relations!' rating=7\n"
     ]
    }
   ],
   "source": [
    "# 结构化输出\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Article(BaseModel):\n",
    "    title: str = Field(description=\"文章标题\")\n",
    "    tags: List[str] = Field(description=\"文章标签\")\n",
    "    summary: str = Field(description=\"文章摘要\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一位专业的技术文章作者，请根据下面的主题，生成对应的文章标题、标签和摘要。\"),\n",
    "    (\"human\", \"主题: {topic}\")\n",
    "])\n",
    "\n",
    "structured_llm = llm.with_structured_output(Article)\n",
    "\n",
    "chain = prompt | structured_llm\n",
    "resp = chain.invoke({\"topic\": \"为‘LangChain JSON输出’生成标题、标签和摘要\"})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb992e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'category': '商品', 'items': [{'name': 'iPhone', 'price': 9999.0, 'tags': []}, {'name': '牛奶', 'price': 6.5, 'tags': []}, {'name': '键盘', 'price': 299.0, 'tags': []}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 使用JsonOutputParser保证结果符合json格式\n",
    "# 只保证是 JSON，可在下游再做 Pydantic 校验\n",
    "parser = JsonOutputParser()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个信息抽取助手。严格输出 JSON，无解释文本。\"),\n",
    "    (\"user\", \"\"\"从以下文本中抽取商品数组，每个包含 name, price(float), tags(list[str])：\n",
    "文本：{text}\n",
    "只输出 JSON，对象形如：{{\"ok\": true, \"category\":\"...\", \"items\":[...]}}\"\"\")\n",
    "])\n",
    "chain = prompt | llm | parser\n",
    "resp = chain.invoke({\"text\": \"iPhone 9999；牛奶 6.5；键盘 299\"})\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a4606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok=True category='other' items=[Item(name='小米平板', price=1999.0, tags=[]), Item(name='黄瓜', price=2.5, tags=[]), Item(name='苹果', price=6.99, tags=[])] notes=None\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers.fix import OutputFixingParser\n",
    "from typing import List, Literal, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name: str = Field(..., description=\"物品名称\")\n",
    "    price: float = Field(..., ge=0, description=\"价格，非负\")\n",
    "    tags: List[str] = Field(default_factory=list, description=\"标签列表\")\n",
    "\n",
    "class Result(BaseModel):\n",
    "    ok: bool = Field(..., description=\"处理是否成功\")\n",
    "    category: Literal[\"food\", \"tech\", \"other\"] = Field(..., description=\"分类\")\n",
    "    items: List[Item] = Field(default_factory=list, description=\"物品数组\")\n",
    "    notes: Optional[str] = Field(None, description=\"备注，可为空\")\n",
    "\n",
    "base_parser = PydanticOutputParser(pydantic_object=Result)\n",
    "parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"请严格按照给定 JSON Schema 输出，无解释。\"),\n",
    "    (\"user\", \"\"\"文本：{text}\n",
    "格式要求：\n",
    "{format_instructions}\n",
    "\"\"\")\n",
    "]).partial(format_instructions=base_parser.get_format_instructions())\n",
    "chain = prompt | llm | parser\n",
    "resp = chain.invoke({\"text\": \"小米平板 1999；黄瓜 2.5; 苹果 6.99\"})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c540d3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
